{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install lda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing as prep\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lda\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3598, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = pd.read_csv('5000data.csv')\n",
    "full = full.dropna()\n",
    "full = full[full['language'] == 'English']\n",
    "full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text mining for plot-keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6519"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = full['plot_keywords'].str.split('|').apply(pd.Series, 1).stack().tolist()\n",
    "vocab = list(set(vocab))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for index, movie in full.iterrows():\n",
    "    plot = movie['plot_keywords'].split('|')\n",
    "    dict_ = {}\n",
    "    for word in vocab:\n",
    "        dict_[word] = 0\n",
    "    for word in plot:\n",
    "        dict_[word] = 1\n",
    "\n",
    "    X.append(dict_)\n",
    "\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83360"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist = list(X.columns)\n",
    "myfile = open('dictionary.csv', \"w\", newline=\"\")\n",
    "wr = csv.writer(myfile, delimiter=',', quotechar=',', quoting=csv.QUOTE_MINIMAL)\n",
    "wr.writerow(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(topic_word): <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=30, n_iter=2000, random_state=1)\n",
    "model.fit(X)\n",
    "\n",
    "topic_word = model.topic_word_\n",
    "print(\"type(topic_word): {}\".format(type(topic_word)))\n",
    "# print(\"shape: {}\".format(topic_word.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Topic 0\n",
      "- president,hotel,photographer,investigation,farm,assassin,television,evil,satire,concert\n",
      "*Topic 1\n",
      "- cia,terrorist,spy,russian,assassin,rescue,rape,bomb,mission,british\n",
      "*Topic 2\n",
      "- police,detective,murder,heist,drugs,gangster,bank,prison,partner,criminal\n",
      "*Topic 3\n",
      "- island,monster,father daughter relationship,gold,alaska,forest,mountain,snow,food,survival\n",
      "*Topic 4\n",
      "- vomiting,coach,basketball,football,title directed by female,high school,college,halloween,teenage girl,two word title\n",
      "*Topic 5\n",
      "- soldier,revenge,ship,army,military,conspiracy,cult film,jew,california,colonel\n",
      "*Topic 6\n",
      "- new york city,love,writer,singer,reporter,band,actress,song,small town,magazine\n",
      "*Topic 7\n",
      "- battle,king,warrior,scientist,island,experiment,england,dragon,orphan,greek\n",
      "*Topic 8\n",
      "- friend,boy,baby,girl,restaurant,book,catholic,twin,france,soccer\n",
      "*Topic 9\n",
      "- death,vampire,murder,blood,1950s,hotel,independent film,team,revenge,artist\n",
      "*Topic 10\n",
      "- drugs,superhero,stripper,male objectification,undercover,cocaine,based on comic book,mutant,dea,toy\n",
      "*Topic 11\n",
      "- train,texas,sheriff,martial arts,violence,hostage,revenge,training,american,19th century\n",
      "*Topic 12\n",
      "- box office flop,critically bashed,one word title,three word title,new york city,fear,hawaii,punctuation in title,village,farmer\n",
      "*Topic 13\n",
      "- friend,love,best friend,friendship,wedding,children,summer,small town,rivalry,letter\n",
      "*Topic 14\n",
      "- fight,dream,nightmare,boxing,bully,jewish,serial killer,post apocalypse,diamond,boxer\n",
      "*Topic 15\n",
      "- male nudity,sex,female nudity,pubic hair,male frontal nudity,male full frontal nudity,hitman,nudity,infidelity,male rear nudity\n",
      "*Topic 16\n",
      "- school,high school,student,friend,party,teacher,college,teenager,gay,professor\n",
      "*Topic 17\n",
      "- princess,magic,sequel,queen,prince,pirate,supernatural power,no opening credits,magician,curse\n",
      "*Topic 18\n",
      "- dog,neighbor,cat,time travel,cancer,box office hit,racism,professor,future,first part\n",
      "*Topic 19\n",
      "- escape,jungle,based on true story,prison,1980s,fire,africa,desert,rescue,1960s\n",
      "*Topic 20\n",
      "- death,birthday,beach,boy,vacation,sequel,island,storm,competition,boat\n",
      "*Topic 21\n",
      "- based on novel,friendship,love,travel,bounty hunter,suburb,christmas,retirement,japan,journey\n",
      "*Topic 22\n",
      "- female protagonist,actor,african american,dance,overalls,family relationships,dancing,dancer,diner,hip hop\n",
      "*Topic 23\n",
      "- christmas,ghost,secret,house,woods,funeral,christmas eve,four word title,mansion,haunted house\n",
      "*Topic 24\n",
      "- alien,robot,planet,future,captain,pilot,escape,astronaut,scientist,rescue\n",
      "*Topic 25\n",
      "- death,doctor,hospital,1970s,suicide,murder,flashback,nurse,memory,psychiatrist\n",
      "*Topic 26\n",
      "- fbi,murder,serial killer,fbi agent,boy,mafia,blood splatter,undercover,on the run,die hard scenario\n",
      "*Topic 27\n",
      "- lawyer,marriage,love,bar,money,new york,new york city,sex,computer,alcoholic\n",
      "*Topic 28\n",
      "- breasts,priest,sex scene,female frontal nudity,creature,demon,found footage,exorcism,apartment,female rear nudity\n",
      "*Topic 29\n",
      "- car accident,money,hospital,virus,zombie,thief,car,faith,museum,california\n"
     ]
    }
   ],
   "source": [
    "# n = 10\n",
    "# for i, topic_dist in enumerate(topic_word):\n",
    "#     topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n+1):-1]\n",
    "#     print('*Topic {}\\n- {}'.format(i, ','.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "pickle.dump(model, open(\"lda.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3598, 30)\n",
      "(3598, 28)\n",
      "(3598, 58)\n"
     ]
    }
   ],
   "source": [
    "index = full.index\n",
    "doc_topic = model.doc_topic_\n",
    "doc_topic = pd.DataFrame(doc_topic, index=index)\n",
    "topic_name = [('topic' + str(i)) for i in range(30)]\n",
    "doc_topic.columns = topic_name\n",
    "print(doc_topic.dropna().shape)\n",
    "print(full.dropna().shape)\n",
    "processed = pd.concat([full, doc_topic], axis=1, join_axes=[full.index]).dropna()\n",
    "print(processed.shape)\n",
    "# movie_title = full.movie_title.tolist()\n",
    "# for i in range(20):\n",
    "#      print(\"{} (top topic: {})\".format(movie_title[i], doc_topic[i].argmax()))\n",
    "\n",
    "del processed['plot_keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genres = processed['genres'].str.split('|').apply(pd.Series).stack().drop_duplicates().tolist()\n",
    "for genre in genres:\n",
    "    processed.insert(processed.shape[1], genre, np.zeros(shape=(processed.shape[0],1)))\n",
    "for index, row in processed.iterrows():\n",
    "    for genre in genres:        \n",
    "        if genre in row['genres']:\n",
    "            processed.set_value(index,genre,1.0)\n",
    "del processed['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie = processed.drop(['facenumber_in_poster', 'title_year', 'Film-Noir', 'color', 'director_name', 'movie_title', 'actor_3_name', 'actor_2_name', 'actor_1_name', 'movie_imdb_link', 'content_rating', 'aspect_ratio', 'language', 'country'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3598, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie = movie.dropna()\n",
    "movie.to_csv('meaningful.csv', index=False)\n",
    "movie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## further processing -- dealing with the mixture of continuous and discrete features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('meaningful.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardize (x - u)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3598, 42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data['gross']\n",
    "del data['gross']\n",
    "data_continuous = data.ix[:,:'topic29']\n",
    "data_discrete = data.ix[:, 'Action':]\n",
    "data_continuous.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = data_continuous.describe()\n",
    "\n",
    "col_names = data_continuous.columns.tolist()\n",
    "for col in col_names:\n",
    "    data_continuous[col] = prep.scale(data_continuous[col].astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d2 = data_continuous.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rescale to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_continuous -= data_continuous.min()\n",
    "data_continuous /= data_continuous.max() - data_continuous.min()\n",
    "data_continuous *= 2\n",
    "data_continuous -= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3598, 64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [data_continuous, data_discrete, target]\n",
    "newData = pd.concat(frames, axis=1)\n",
    "newData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newData.to_csv('rescaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### save mean/std/min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>budget</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>...</th>\n",
       "      <th>topic20</th>\n",
       "      <th>topic21</th>\n",
       "      <th>topic22</th>\n",
       "      <th>topic23</th>\n",
       "      <th>topic24</th>\n",
       "      <th>topic25</th>\n",
       "      <th>topic26</th>\n",
       "      <th>topic27</th>\n",
       "      <th>topic28</th>\n",
       "      <th>topic29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167.959144</td>\n",
       "      <td>110.023624</td>\n",
       "      <td>822.845470</td>\n",
       "      <td>800.038911</td>\n",
       "      <td>8029.099222</td>\n",
       "      <td>107521.360756</td>\n",
       "      <td>11950.276265</td>\n",
       "      <td>341.292107</td>\n",
       "      <td>3.972447e+07</td>\n",
       "      <td>2100.710117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031027</td>\n",
       "      <td>0.030955</td>\n",
       "      <td>0.032679</td>\n",
       "      <td>0.031668</td>\n",
       "      <td>0.037181</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.035756</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.032810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.501918</td>\n",
       "      <td>22.198206</td>\n",
       "      <td>3111.794348</td>\n",
       "      <td>1929.937188</td>\n",
       "      <td>15780.513679</td>\n",
       "      <td>153724.786732</td>\n",
       "      <td>19411.434800</td>\n",
       "      <td>414.049811</td>\n",
       "      <td>4.371675e+07</td>\n",
       "      <td>4627.174791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.070052</td>\n",
       "      <td>0.070830</td>\n",
       "      <td>0.071616</td>\n",
       "      <td>0.087466</td>\n",
       "      <td>0.073814</td>\n",
       "      <td>0.075631</td>\n",
       "      <td>0.076858</td>\n",
       "      <td>0.072546</td>\n",
       "      <td>0.074268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.333170</td>\n",
       "      <td>-3.290076</td>\n",
       "      <td>-0.264465</td>\n",
       "      <td>-0.414599</td>\n",
       "      <td>-0.508869</td>\n",
       "      <td>-0.698946</td>\n",
       "      <td>-0.615716</td>\n",
       "      <td>-0.814730</td>\n",
       "      <td>-9.087999e-01</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270590</td>\n",
       "      <td>-0.263481</td>\n",
       "      <td>-0.284937</td>\n",
       "      <td>-0.267694</td>\n",
       "      <td>-0.282214</td>\n",
       "      <td>-0.283505</td>\n",
       "      <td>-0.286803</td>\n",
       "      <td>-0.302629</td>\n",
       "      <td>-0.260567</td>\n",
       "      <td>-0.273505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.181691</td>\n",
       "      <td>9.911024</td>\n",
       "      <td>7.127797</td>\n",
       "      <td>11.504544</td>\n",
       "      <td>40.053116</td>\n",
       "      <td>10.294128</td>\n",
       "      <td>33.221107</td>\n",
       "      <td>11.398058</td>\n",
       "      <td>8.013501e+00</td>\n",
       "      <td>29.157757</td>\n",
       "      <td>...</td>\n",
       "      <td>8.857867</td>\n",
       "      <td>8.659726</td>\n",
       "      <td>8.540259</td>\n",
       "      <td>8.460653</td>\n",
       "      <td>6.864398</td>\n",
       "      <td>8.184922</td>\n",
       "      <td>7.978207</td>\n",
       "      <td>7.830329</td>\n",
       "      <td>8.355887</td>\n",
       "      <td>8.143096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_critic_for_reviews    duration  director_facebook_likes  \\\n",
       "0              167.959144  110.023624               822.845470   \n",
       "1              124.501918   22.198206              3111.794348   \n",
       "2               -1.333170   -3.290076                -0.264465   \n",
       "3                5.181691    9.911024                 7.127797   \n",
       "\n",
       "   actor_3_facebook_likes  actor_1_facebook_likes  num_voted_users  \\\n",
       "0              800.038911             8029.099222    107521.360756   \n",
       "1             1929.937188            15780.513679    153724.786732   \n",
       "2               -0.414599               -0.508869        -0.698946   \n",
       "3               11.504544               40.053116        10.294128   \n",
       "\n",
       "   cast_total_facebook_likes  num_user_for_reviews        budget  \\\n",
       "0               11950.276265            341.292107  3.972447e+07   \n",
       "1               19411.434800            414.049811  4.371675e+07   \n",
       "2                  -0.615716             -0.814730 -9.087999e-01   \n",
       "3                  33.221107             11.398058  8.013501e+00   \n",
       "\n",
       "   actor_2_facebook_likes    ...      topic20   topic21   topic22   topic23  \\\n",
       "0             2100.710117    ...     0.031027  0.030955  0.032679  0.031668   \n",
       "1             4627.174791    ...     0.068477  0.070052  0.070830  0.071616   \n",
       "2               -0.454057    ...    -0.270590 -0.263481 -0.284937 -0.267694   \n",
       "3               29.157757    ...     8.857867  8.659726  8.540259  8.460653   \n",
       "\n",
       "    topic24   topic25   topic26   topic27   topic28   topic29  \n",
       "0  0.037181  0.033424  0.034188  0.035756  0.031400  0.032810  \n",
       "1  0.087466  0.073814  0.075631  0.076858  0.072546  0.074268  \n",
       "2 -0.282214 -0.283505 -0.286803 -0.302629 -0.260567 -0.273505  \n",
       "3  6.864398  8.184922  7.978207  7.830329  8.355887  8.143096  \n",
       "\n",
       "[4 rows x 42 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame(d1.loc['mean'])\n",
    "d = d.transpose()\n",
    "d = d.append(d1.loc['std'], ignore_index=True)\n",
    "d = d.append(d2.loc['min'], ignore_index=True)\n",
    "d = d.append(d2.loc['max'], ignore_index=True)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.to_csv(\"statistics.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_critic_for_reviews       1.679591e+02\n",
       "duration                     1.100236e+02\n",
       "director_facebook_likes      8.228455e+02\n",
       "actor_3_facebook_likes       8.000389e+02\n",
       "actor_1_facebook_likes       8.029099e+03\n",
       "num_voted_users              1.075214e+05\n",
       "cast_total_facebook_likes    1.195028e+04\n",
       "num_user_for_reviews         3.412921e+02\n",
       "budget                       3.972447e+07\n",
       "actor_2_facebook_likes       2.100710e+03\n",
       "imdb_score                   6.427043e+00\n",
       "movie_facebook_likes         9.491271e+03\n",
       "topic0                       3.338895e-02\n",
       "topic1                       3.495232e-02\n",
       "topic2                       3.788054e-02\n",
       "topic3                       3.114233e-02\n",
       "topic4                       3.230733e-02\n",
       "topic5                       3.219616e-02\n",
       "topic6                       3.383067e-02\n",
       "topic7                       3.334759e-02\n",
       "topic8                       3.481336e-02\n",
       "topic9                       3.347763e-02\n",
       "topic10                      3.227722e-02\n",
       "topic11                      3.464461e-02\n",
       "topic12                      3.144508e-02\n",
       "topic13                      3.470913e-02\n",
       "topic14                      3.342369e-02\n",
       "topic15                      3.155923e-02\n",
       "topic16                      3.658517e-02\n",
       "topic17                      3.249560e-02\n",
       "topic18                      3.203403e-02\n",
       "topic19                      3.240130e-02\n",
       "topic20                      3.102653e-02\n",
       "topic21                      3.095473e-02\n",
       "topic22                      3.267923e-02\n",
       "topic23                      3.166842e-02\n",
       "topic24                      3.718074e-02\n",
       "topic25                      3.342369e-02\n",
       "topic26                      3.418801e-02\n",
       "topic27                      3.575634e-02\n",
       "topic28                      3.140041e-02\n",
       "topic29                      3.280993e-02\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
